##  Elasticsearch是一个基于Lucene的搜索引擎

## 倒排索引:
> 传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。
    而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。
    有了倒排索引，就能实现o（1）时间复杂度的效率检索文章了，极大的提高了检索效率。  
- 倒排索引，相反于一篇文章包含了哪些词，它从词出发，记载了这个词在哪些文档中出现过，由两部分组成——词典和倒排表。

- 结构：
    - Term index：
        - 尽量少的读磁盘，有必要把一些数据缓存到内存里
        - 整个term dictionary本身又太大了，无法完整地放到内存里
        - term index是一棵trie 树，这棵树不会包含所有的term，它包含的是term的一些前缀
        - 通过term index可以快速地定位到term dictionary的某个offset，然后从这个位置再往后顺序查找。
        - term index在内存中是以FST（finite state transducers）的形式保存
            - 空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；
            - 查询速度快。O(len(str))的查询时间复杂度。
    - term dictionary：对 term 排序，二分查找， logN 次磁盘查找得到目标
    - posting list：是一个int的数组，存储了所有符合某个term的文档id
 

## 在并发情况下，Elasticsearch如果保证读写一致？    
- 可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；  
- 对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。       
    但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。    
    - quorum:默认值，要求所有的shard中，必须是大部分的shard都是活跃的，可用的，才可以执行这个写操作。      
    - one:要求我们这个写操作，只要有一个primary shard是active状态，就可以执行。 
    - all:必须所有的primary shard和replica shard都是活跃的，才可以执行这个写操作。     
- 对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；   
    如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。    


## Elasticsearch对于大数据量（上亿量级）的聚合如何实现？
> Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关


## 对于GC方面，在使用Elasticsearch时要注意什么？
- 倒排词典的索引需要常驻内存，无法GC，需要监控data node上segment memory增长趋势。
- 各类缓存，field cache, filter cache, indexing cache, bulk queue等等，要设置合理的大小
    - 并且要应该根据最坏的情况来看heap是否够用
    - 也就是各类缓存全部占满的时候，还有heap空间可以分配给其他任务吗？
    - 避免采用clear cache等“自欺欺人”的方式来释放内存。
- 避免返回大量结果集的搜索与聚合。确实需要大量拉取数据的场景，可以采用scan & scroll api来实现。
- cluster stats驻留内存并无法水平扩展，超大规模集群可以考虑分拆成多个集群通过tribe node连接。


## 详细描述一下Elasticsearch搜索的过程。
- 搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；
- 在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 
    - 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。
    - PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。
    - 每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。
- 接下来就是取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。
- 每个分片加载并丰富文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。
- 补充：
    - Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确
    - DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。

## 详细描述一下Elasticsearch更新和删除文档的过程
- 删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；
- 磁盘上的每个段都有一个相应的.del文件。
 - 当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。
 - 该文档依然能匹配查询，但是会在结果中被过滤掉。
 - 当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。
- 在新的文档被创建时，Elasticsearch会为该文档指定一个版本号
    - 当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。
    - 旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。

## 详细描述一下Elasticsearch索引文档的过程。(即写文件过程)
- 协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。
- 当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，
    - 这个从Momery Buffer到Filesystem Cache的过程就叫做refresh；
- 当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。
    - 其实现机制是接收到请求后，同时也会写入到translog中，
    - 当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；
- 在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，
    - 段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。
- flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；


## 关于Lucene的Segement
- Lucene索引是由多个段组成，段本身是一个功能齐全的倒排索引。
- 段是不可变的，允许Lucene将新的文档增量地添加到索引中，而不用从头重建索引。
- 对于每一个搜索请求而言，索引中的所有段都会被搜索，并且每个段会消耗CPU的时钟周、文件句柄和内存。
    - 这意味着段的数量越多，搜索性能会越低。
- 为了解决这个问题，Elasticsearch会合并小段到一个较大的段，提交新的合并段到磁盘，并删除那些旧的小段。


## Elasticsearch是如何实现Master选举的
- Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping和Unicast这两部分
    - Ping：节点之间通过这个RPC来发现彼此
    - Unicast：单播模块包含一个主机列表以控制哪些节点需要ping通
- 对所有可以成为master的节点（node.master: true）根据nodeId字典排序，
    - 每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。
- 如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。
    - 否则重新选举一直到满足上述条件。

## Elasticsearch在部署时，对Linux的设置有哪些优化方法
- 关闭缓存 swap
- 设置最大文件句柄数

## 分片和复制（shards and replicas）
- Elasticsearch提供了将索引划分成多片的能力，这些片叫做分片
    - 允许在分片（位于多个节点上）之上进行分布式的、并行的操作，进而提高性能
- Elasticsearch允许创建分片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。
    - 在分片失败的情况下，复制提供了高可用性。
    - 复制分片不与原分片置于同一节点上是非常重要的。 
    - 因为搜索可以在所有的复制上并行运行，复制可以扩展搜索量.
    - 每个索引可以被分成多个分片。一个索引也可以被复制0次（即没有复制） 或多次。
    - 一旦复制了，每个索引就有了主分片（作为复制源的分片）和复制分片（主分片的拷贝）。 
    - 分片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你不能再改变分片的数量。